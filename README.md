<h1 align="center">Hi There, I'm Ahmed Nagib <img  src="https://raw.githubusercontent.com/ABSphreak/ABSphreak/master/gifs/Hi.gif" width="30px"></h1>
<p align="center">
<a target="_blank" href="https://www.linkedin.com/in/ahmednagib"><img src="https://img.shields.io/badge/-LinkedIn-0077B5?style=for-the-badge&logo=Linkedin&logoColor=white"></img></a>
<a target="_blank" href="mailto:nagibs@gmail.com"><img src="https://img.shields.io/badge/-Gmail-D14836?style=for-the-badge&logo=Gmail&logoColor=white"></img></a>
<a target="_blank" href="https://twitter.com/ANagib"><img src="https://img.shields.io/badge/-Twitter-1DA1F2?style=for-the-badge&logo=Twitter&logoColor=white"></img></a>
<a target="_blank" href="https://public.tableau.com/app/profile/ahmed.nagib"><img src="https://img.shields.io/badge/-Tableau-E97627?style=for-the-badge&logo=Tableau&logoColor=white"></img></a>
<a target="_blank" href="https://github.com/nagibs/">
<img src="https://img.shields.io/badge/-Github-100000?&style=for-the-badge&logo=github&logoColor=white"></a>
</p>
<hr>

## Know More About Me? üë®‚Äçüíª üòÑ
Originally an Engineering team leader and a Project Manager with 13+ years of professional experience in the telecommunication industry who is pivoting into Data Science.

This aligns naturally with my superior analytical and planning skills. Data analytics, delivering actionable insights, taking data driven decisions, creating and presenting dashboards for all levels of stakeholders was somehow a day-to-day work, beside planning and managing multi-million-dollars projects.

- üí° I'm interested in all things data: **Data Science, Machine Learning, Data Engineering, Big Data and Cloud**  
- üì´ How to reach me? Through [**Email**](mailto:nagibs@gmail.com) or [**LinkedIn**](https://www.linkedin.com/in/ahmednagib/)
- üå± I‚Äôm currently pursuing **a career in Data**
- ‚ö° **Fun fact:** I have an ***infinite*** appetite to learn and grow
- üî≠ I‚Äôm currently working on:
 	- [ ] [Andrew Ng's Machine Learning Specialization](https://www.coursera.org/specializations/machine-learning-introduction)
		- [x] [Supervised Machine Learning: Regression and Classification](https://www.coursera.org/learn/machine-learning)
		- [X] [Advanced Learning Algorithms](https://www.coursera.org/learn/advanced-learning-algorithms)
		- [ ] [Unsupervised Learning, Recommenders, Reinforcement Learning](https://www.coursera.org/learn/unsupervised-learning-recommenders-reinforcement-learning)
	- [ ] AWS
		- [ ] [AWS Machine Learning Engineer](https://www.udacity.com/course/aws-machine-learning-engineer-nanodegree--nd189)


## My Certificates and Courses üìú üéì ‚úîÔ∏è
<details><summary><b><a href="https://www.coursera.org/specializations/ibm-data-science" target="_blank">IBM Data Science Professional</a> - by IBM <a href="https://coursera.org/verify/professional-cert/3EHX5A3P8DDT" target="_blank">[Certificate]</a></b></summary>
<br>

- ***Course Summary:***
    - The program consists of 9 online courses in addition to a capstone project.
    - In this Professional Certificate, learners developed and honed hands on skills in Data Science and Machine Learning. Staring with an orientation of Data Science and its Methodology, became familiar and used a variety of data science tools, learned Python and SQL, performed Data Visualization and Analysis, and created Machine Learning models using real data science tools and real-world data sets.
    - This Professional Certificate has a strong emphasis on applied learning. Except for the first course, all other courses include a series of hands-on labs in the IBM Cloud that will give you practical skills with applicability to real jobs.
- <details><summary><b><i>Program Courses:</i></b></summary>

    1. [**What is Data Science?**](https://www.coursera.org/learn/what-is-datascience) - [[Certificate]](https://coursera.org/verify/KLD4DURKX578)
    2. [**Tools for Data Science**](https://www.coursera.org/learn/open-source-tools-for-data-science) - [[Certificate]](https://coursera.org/verify/XXJFBRQCLUPK)
    3. [**Data Science Methodology**](https://www.coursera.org/learn/data-science-methodology) - [[Certificate]](https://coursera.org/verify/QBPN8V6472WE)
    4. [**Python for Data Science, AI & Development**](https://www.coursera.org/learn/python-for-applied-data-science-ai) - [[Certificate]](https://coursera.org/verify/TCQXE9HQ9X9D)
    5. [**Python Project for Data Science**](https://www.coursera.org/learn/python-project-for-data-science) - [[Certificate]](https://coursera.org/verify/XFGYCTHMXQ5H)
    6. [**Databases and SQL for Data Science with Python**](https://www.coursera.org/learn/sql-data-science) - [[Certificate]](https://coursera.org/verify/8CMNSXBK4TS3)
    7. [**Data Analysis with Python**](https://www.coursera.org/learn/data-analysis-with-python) - [[Certificate]](https://coursera.org/verify/2P9H4FS93WKN)
    8. [**Data Visualization with Python**](https://www.coursera.org/learn/python-for-data-visualization) - [[Certificate]](https://coursera.org/verify/ZUG5SSSLBXG2)
    9. [**Machine Learning with Python**](https://www.coursera.org/learn/machine-learning-with-python) - [[Certificate]](https://coursera.org/verify/9HFGFYTG58M7)
    10. [**Applied Data Science Capstone**](https://www.coursera.org/learn/applied-data-science-capstone) - [[Certificate]](https://coursera.org/verify/5NJ9RF9GMF7S)</details>

- ***Tools:*** Python, SQL, Jupyter / JupyterLab, GitHub, and Watson Studio
- ***Libraries:*** Pandas, NumPy, Matplotlib, Seaborn, Folium, ipython-sql, Scikit-learn, ScipPy, etc.
- ***Projects:***
	- [Applied Data Science Capstone Project](https://github.com/Nagibs/IBM-Applied-Data-Science-Capstone)
	- Random album generator, predict housing prices, best classifier model, Predicting successful rocket landing, dashboard and interactive map.
- ***Techniques:*** Web scraping, data collection, data visualization, data analysis, statistical analysis, and machine learning</details>

<details><summary><b><a href="https://egfwd.com/specializtion/machine-learning/" target="_blank">Machine Learning Cross-Skilling Nanodegree</a> - by Udacity <a href="https://confirm.udacity.com/LMDTDGSV" target="_blank">[Certificate]</a></b></summary>
<br>

- ***Course Summary:***
    - Advanced machine learning techniques and algorithms.
    - Covering wide varity of supervised and unsupervised machine learning techniques and algorithms.
    - Part of Egypt Future Work is Digitial **(EgyFWD)** initiative and sponsored by The Egyptian Ministry of Communications and Information technology **(MCIT)**.<br><br>
- <details><summary><b><i>Course Content:</i></b></summary>        

    - **Supervised Learning**:
        - **Linear Regression:** Linear regression is one of the most fundamental algorithms in machine learning. In this lesson, learn how linear regression works.
        - **Perceptron Algorithm:** The perceptron algorithm is an algorithm for classifying data. It is the building block of neural networks.
        - **Decision Trees:** Decision trees are a structure for decision-making where each decision leads to a set of consequences or additional decisions.
        - **Naive Bayes:** Naive Bayesian Algorithms are powerful tools for creating classifiers for incoming labeled data. Specifically Naive Bayes is frequently used with text data and classification problems.
        - **Support Vector Machines (SVM):** Support vector machines are a common method used for classification problems. They have been proven effective using what is known as the 'kernel' trick!
        - **Ensemble Methods:** Bagging and boosting are two common ensemble methods for combining simple algorithms to make more advanced models that work better than the simple algorithms would on their own.
        - **Model Evaluation Metrics:** Learn the main metrics to evaluate models, such as accuracy, precision, recall, and more!
        - **Training and Tuning:** Learn the main types of errors that can occur during training, and several methods to deal with them and optimize your machine learning models.
        - **Finding Donors (Project):** After covering a wide variety of methods for performing supervised learning, now it's time to put those into action!
    - **Unsupervised Learning**:
        - **Clustering:** Clustering is one of the most common methods of unsupervised learning. Here, we'll discuss the K-means clustering algorithm.
        - **Hierarchical and Density Based Clustering:** We continue to look at clustering methods. Here, we'll discuss hierarchical clustering and density-based clustering (DBSCAN).
        - **Gaussian Mixture Models and Cluster Validation:** In this lesson, we discuss Gaussian mixture model clustering. We then talk about the cluster analysis process and how to validate clustering results. 
        - **Dimensionality Reduction and PCA:** Often we need to reduce a large number of features in our data to a smaller, more relevant set. Principal Component Analysis, or PCA, is a method of feature extraction and dimensionality reduction.
        - **Random Projection and ICA:** In this lesson, we will look at two other methods for feature extraction and dimensionality reduction: Random Projection and Independent Component Analysis (ICA).
        - **Identify Customer Segments (Project):** In this project, you'll apply your unsupervised learning skills to two demographics datasets, to identify segments and clusters in the population, and see how customers of a company map to them.</details>

        - ***Tools & Libraries:*** Python, Jupyter / JupyterLab, Scikit-Learn and GitHub
            - ***Projects:*** 
                - [Finding Donors for CharityML](https://github.com/Nagibs/Finding-Donors-for-Charity-ML-Project)
                - Identify Customer Segments
        - ***Techniques:*** Supervised machine learning, Unsupervised machine learning, ensemble methods, models evaluation and fine-tuning.</details>

<details><summary><b><a href="https://egfwd.com/specializtion/data-analysis-advanced/" target="_blank">Advanced Data Analysis Nanodegree</a> - by Udacity <a href="https://confirm.udacity.com/L9A7KUFE" target="_blank">[Certificate]</a></b></summary>
<br>

- ***Course Summary:***
    - You‚Äôll learn to manipulate and prepare data for analysis, and create visualizations for data exploration. Finally, you‚Äôll learn to use your data skills to tell a story with data.
    - **SQL for Data Analysis:**
        - Learn to query data from multiple places, join the data together, and answer the question using SQL for data analysis
    - **Practical Statistics:**
        - Apply inferential statistics and probability to real-world scenarios using Python
        - Create and analyze the results of hypothesis testing
        - Create and analyze A/B test results
        - Build regression models in Python
    - **Data Visualization:**
        - Build visualizations using different design elements
        - Use visualizations to explore your data
        - Use visualizations to communicate your insights
    - Part of Egypt Future Work is Digitial **(EgyFWD)** initiative and sponsored by The Egyptian Ministry of Communications and Information technology **(MCIT)**.<br><br>
- <details><summary><b><i>Course Content:</i></b></summary>

    - **SQL for Data Analysis:**
        - **Basic SQL:** SQL basics for working with a single table. Learn the key commands to filter a table in many different ways.
        - **SQL Joins:** Learn how to combine data from multiple tables together.
        - **SQL Aggregations:** Learn how to aggregate data using SQL functions
        - **SQL Subqueries & Temporary Tables:** Learn about subqueries, a fundamental advanced SQL topic. This lesson will walk you through the appropriate applications of subqueries, the different types of subqueries, and review subquery syntax and examples.
        - **Query a Digital Music Store Database (Project):** Use a digital music store database to help the company see how they might optimize their business practices.
    - **Practical Statistics:**
        - **Descriptive Statistics - Part I:** Learn about data types, measures of center, and the basics of statistical notation.
        - **Descriptive Statistics - Part II:**  Learn about measures of spread, shape, and outliers as associated with quantitative data. You will also get a first look at inferential statistics.
        - **Admissions Case Study:** Learn to ask the right questions, as you learn about Simpson's Paradox.
        - **Probability:** Gain the basics of probability using coins and die.
        - **Binomial Distribution:** Learn about one of the most popular distributions in probability - the Binomial Distribution.
        - **Conditional Probability:** Not all events are independent. Learn the probability rules for dependent events.
        - **Bayes Rule:** Learn one of the most popular rules in all of statistics - Bayes rule.
        - **Python Probability Practice:** Take what you have learned in the last lessons and put it to practice in Python.
        - **Normal Distribution Theory:** Learn the mathematics behind moving from a coin flip to a normal distribution.
        - **Sampling distributions and the Central Limit Theorem:** Learn all about the underpinning of confidence intervals and hypothesis testing - sampling distributions.
        - **Confidence Intervals:** Learn how to use sampling distributions and bootstrapping to create a confidence interval for any parameter of interest.
        - **Case Study: A/B tests.**
        - **Regression:** Use python to fit linear regression models, as well as understand how to interpret the results of linear models.
        - **Multiple Linear Regression:** Learn to apply multiple linear regression models in python. Learn to interpret the results and understand if your model fits well.
        - **Logistic Regression:** Learn to apply logistic regression models in python. Learn to interpret the results and understand if your model fits well.
        - **Analyze A/B Test Results (Project):** You will be working to understand the results of an A/B test run by an e-commerce website. Your goal is to work through to help the company understand if they should implement the new page design.<br><br>
    - **Data Visualization:**
        - **Introduction to Data Visualization:** Learn to evaluate the quality of data visualizations and build high quality visualizations, starting with the fundamentals of data dashboards.
        - **Design:** Learn to implement the best design practices, and to use the most appropriate chart for a particular situation.
        - **Data Visualizations in Tableau:** Learn to build data visualizations in Tableau using data hierarchies, filters, groups, sets, and calculated fields, as well as create map-based data visualizations in Tableau.
        - **Make Dashboards & Stories in Tableau:** In this final lesson you learn how to build interactive Tableau dashboards and tell impactful stories using data.
        - **Flight Delays Dashboard - (Data Visualization Project):** Build interactive dashboards with Tableau and use them to discover and communicate insights from data.</details>

        - ***Tools & Libraries:*** Python, Jupyter, SQL, Scipy, Tableau, Scikit-Learn.
        - ***Projects:*** 
            - [Analyze A/B Test Results](https://github.com/Nagibs/Analyze-AB-Test-Results)
            - [Flight Delays Dashboard - Data Visualization with Tableau](https://public.tableau.com/views/BuildDataDashboards-FlightDelays/FlightDelaysDashboard?:language=en-US&:display_count=n&:origin=viz_share_link)
        - ***Techniques:*** Statistical analysis, A/B test analysis, data visualization</details>
    
<details><summary><b><a href="https://egfwd.com/specializtion/data-analysis-professional/" target="_blank">Data Analysis Professional Nanodegree</a> - by Udacity <a href="https://confirm.udacity.com/MZKFFVKH" target="_blank">[Certificate]</a></b></summary>
<br>

- ***Course Summary:***
    - Advance your programming skills and refine your ability to work with messy, complex datasets. You‚Äôll learn to manipulate and prepare data for analysis, and create visualizations for data exploration. Finally, you‚Äôll learn to use your data skills to tell a story with data.
    - **Introduction to Python Programming:**
        - Develop programs in Python
        - Manipulate data using NumPy
        - Load and process data using Pandas
    - **Introduction to Data Analysis:**
        - Use Anaconda to manage your programming environment
        - Investigate a dataset using Python data analysis packages
        - Perform the entire data analysis process on a dataset
    - **Data Wrangling:**
        - Gather data from multiple sources in a variety of formats
        - Assess the quality and tidiness of data visually and programmatically
        - Clean data using Python and Pandas
    - Part of Egypt Future Work is Digitial **(EgyFWD)** initiative and sponsored by The Egyptian Ministry of Communications and Information technology **(MCIT)**.<br><br>
- <details><summary><b><i>Course Content:</i></b></summary>

    - **Introduction to Python:**
        - **Data Types and Operators:** Familiarize yourself with the building blocks of Python. Learn about data types and operators, built-in functions, type conversion, whitespace, and style guidelines.
        - **Data Structures:** Use data structures to order and group different data types together! Learn about the types of data structures in Python, along with more useful built-in functions and operators.
        - **Control Flow:** Build logic into your code with control flow tools! Learn about conditional statements, repeating code with loops and useful built-in functions, and list comprehensions.
        - **Functions:** Learn how to use functions to improve and reuse your code! Learn about functions, variable scope, documentation, lambda expressions, iterators, and generators.
        - **Scripting:** Setup your own programming environment to write and run Python scripts locally! Learn good scripting practices, interact with different inputs, and discover awesome tools.
        - **NumPy:** Learn the basics of NumPy and how to use it to create and manipulate arrays.
        - **Pandas:** Learn the basics of Pandas Series and DataFrames and how to use them to load and process data.
        - **Explore US Bikeshare Data (Project):** Use Python to understand U.S. bikeshare data. Calculate statistics and build an interactive environment where a user chooses the data and filter for a dataset to analyze.
    - **Introduction to Data Analysis:**
        - **Jupyter Notebooks:** Jupyter Notebooks are a great tool for getting started with writing python code. Though in production you often will write code in scripts, notebooks are wonderful for sharing insights and data visualization.
        - **The Data Analysis Process:** Learn about the data analysis process and practice investigating different datasets using Python and its powerful packages for data analysis.
        - **Gathering Data:** Gather data from various sources and a variety of file formats using Python. Rotten Tomatoes ratings, Roger Ebert reviews, and Wikipedia movie poster images make up the dataset for this lesson.
        - **Data Analysis Process - Case Study 1:** Investigate a dataset on chemical properties and quality ratings of wine samples by going through the entire data analysis process and building more skill with Python for data analysis.
        - **Data Analysis Process - Case Study 2:** Investigate a more challenging dataset on fuel economy and learn more about problems and strategies in data analysis. Continue to build on your Python for data analysis skills.
        - **Investigate a Dataset (Project):** Choose one of Udacity's curated datasets, perform an investigation, and share your findings.
    - **Data Wrangling:**
        - **Introduction to Data Wrangling:** Identify each step of the data wrangling process (gathering, assessing, and cleaning) through a brief walkthrough of the process. The dataset for this lesson is an online job postings dataset from Kaggle.
        - **Gathering Data:** Gather data from various sources and a variety of file formats using Python. Rotten Tomatoes ratings, Roger Ebert reviews, and Wikipedia movie poster images make up the dataset for this lesson.
        - **Assessing Data:** Assess data visually and programmatically for quality and tidiness issues using pandas. The dataset for this lesson is mock Phase II clinical trial data for a new oral insulin called Auralin.
        - **Cleaning Data:** Using Pandas, clean the quality and tidiness issues you identified in the "Assessing Data" lesson. The dataset is the same: mock Phase II clinical trial data for a new oral insulin called Auralin</details>

        - ***Tools & Libraries:*** Python, Jupyter, NumPy, Pandas, Matplotlib. 
        - ***Projects:*** 
            - [Explore US Bikeshare Data](https://github.com/Nagibs/Explore-US-Bikeshare-Data)
            - [No-show appointments Dataset Analysis](https://github.com/Nagibs/Investigating-No-Show-Appointments-Dataset/blob/4a2b87d8824eba270847385eee1aee0e581dc49a/Investigate_No-Show_dataset.ipynb)
        - ***Techniques:*** Python programming, python data structure, data wrangling, scripting</details>

<details><summary><b><a href="https://www.coursera.org/learn/sql-data-science" target="_blank">Databases and SQL for Data Science with Python</a> - by IBM <a href="https://coursera.org/verify/8CMNSXBK4TS3" target="_blank">[Certificate]</a></b></summary>
<br>

- ***Course Summary:***
    - Learn and apply foundational knowledge of the SQL language. It is also intended to get you started with performing SQL access in a data science environment.
    - Work with real databases, real data science tools, and real-world datasets
    - Create a database instance in the cloud. Through a series of hands-on labs you will practice building and running SQL queries.
    - Build more powerful queries with advanced SQL techniques like views, transactions, stored procedures and joins.
- <details><summary><b><i>Course Content:</i></b></summary>
    
    - **Getting Started with SQL:** You will create a database instance on the cloud. Learn some of the basic SQL statements. Also write and practice basic SQL hands-on on a live database.
    - **Introduction to Relational Databases and Tables:** Explore the fundamental concepts behind databases, tables, and the relationships between them. Create an instance of a database, discover SQL statements that allow you to create and manipulate tables, and then practice them on your own live database.
    - **Intermediate SQL:** Learn how to use string patterns and ranges to search data and how to sort and group data in result sets. Also practice composing nested queries and execute select statements to access data from multiple tables.
    - **Accessing Databases using Python:** Learn the basic concepts related to using Python to connect to databases. In a Jupyter Notebook, you will create tables, load data, query data using SQL, and analyze data using Python.
    - **Course Assignment:** Working with multiple real world datasets for the city of Chicago. You will be asked questions that will help you understand the data just as you would in the real wold.
    - **Bonus Module:Advanced SQL for Data Engineering (Honors):** This module covers some advanced SQL techniques that will be useful for Data Engineers. Learn how to build more powerful queries with advanced SQL techniques like views, transactions, stored procedures and joins.</details>
    - ***Tools & Libraries:*** Python, SQL, IBM DB2. 
    - ***Projects:*** 
        - Chicago City Datasets Analysis with SQL</details>
		
<details><summary><b><a href="https://www.coursera.org/learn/introduction-mongodb" target="_blank">Introduction to MongoDB</a> - by MongoDB <a href="https://coursera.org/verify/NQUJMQR96DN5" target="_blank">[Certificate]</a></b></summary>
<br>

- ***Course Summary:***
    - Start by mastering the fundamentals of MongoDB, including:
        - MongoDB‚Äôs Document data model, importing data into a cluster.
        - Working with our CRUD API and Aggregation Framework.
        - Taught through a demo application which will give you a great first encounter of how simple and practical it can be to build applications with MongoDB
    - learn and work with useful MongoDB tools and services: 
        - Work with Atlas, MongoDB's database as a service.
        - MongoDB Compass, a schema visualization tool.
        - As well as many other useful command-line utilities.
- ***Tools & Libraries:*** MongoDB, Python, Atlas, MongoDB Compass</details>


<details><summary><b><a href="https://www.coursera.org/learn/unix" target="_blank">The Unix Workbench</a> - by Johns Hopkins University <a href="https://coursera.org/verify/EL6B3XU9RM3P" target="_blank">[Certificate]</a></b></summary>
<br>

- ***Course Summary:***
    - Command line interfaces can seem alien at first, so this course attempts to draw parallels between using the command line and actions that you would normally take while using your mouse and keyboard.
    - Learn how to write little pieces of software in Bash, which allows you to connect together the tools we‚Äôll discuss.
    - By the end of this course you be able to use different Unix tools as if they‚Äôre interconnecting Lego bricks.<br><br>
- <details><summary><b><i>Course Content:</i></b></summary>        

    - **Unix and Command Line Basics:** Get access to Unix (you may already be using it), and you'll start using the command line. We'll draw parallels between using your mouse and keyboard with your computer's graphics versus only using the command line.
    - **Working with Unix:** Get into the power of different Unix tools. We'll walk through several scenarios where you could use Unix to perform tasks at a much faster speed than you would be able to normally.
    - **Bash Programming:** Unleash the command line's usefulness as a programming language. By the end of this week you'll be writing your own little computer programs that you can use on the command line.
    - **Git and GitHub:** Learn how to use Git, which is like "track changes" for your code and plain text files, but much more powerful. We'll then explore how to use Git with GitHub, a social coding network where you can publish you projects and explore other's code.
    - **Nephology:** Set up a cloud computing environment so we can explore how computers communicate with each other using the internet.
- ***Tools & Libraries:*** VM VirtualBox, Unix, Bash
- ***Techniques:*** Shell scripting, Github, Bash, Cloud Computing.</details>

<details><summary><b><a href="https://www.coursera.org/account/accomplishments/certificate/QQTQCB4HLCQC" target="_blank">Introduction to Big Data</a> - by University of California San Diego <a href="https://coursera.org/verify/QQTQCB4HLCQC" target="_blank">[Certificate]</a></b></summary>
<br>

- ***Course Summary:***
    - An introductonary course to the Big Data landscape.
    - An introduction to one of the most common frameworks, Hadoop.
    - Explain the V‚Äôs of Big Data (volume, velocity, variety, veracity, valence, and value) and why each impacts data collection, monitoring, storage, analysis and reporting.
    -  Summarize the features and value of core Hadoop stack components including the YARN resource and job management system, the HDFS file system and the MapReduce programming model.<br><br>
- <details><summary><b><i>Course Content:</i></b></summary>
    
    - **Big Data: Why and Where?:** Data has been around (even digitally) for a while. What makes data "big" and where does this big data come from?
    - **Characteristics of Big Data and Dimensions of Scalability:** The "Big Vs". Examples and descriptions of the commonly discussed 5 Vs. Propose a 6th V, and practice writing Big Data questions targeting this V -- value.
    - **Data Science: Getting Value out of Big Data:** The reality is we care about Big Data because it can bring value to our companies, our lives, and the world. In this module we introduce a 5 step process for approaching data science problems.
    - **Foundations for Big Data Systems and Programming:** Big Data requires new programming frameworks and systems. Give you a grounding in some of the key concepts.</details>
        
    - ***Techniques:*** Big Data, Apache Hadoop, Mapreduce, Cloudera, YARN.</details>

<details><summary><b><a href="https://www.coursera.org/learn/spark-sql" target="_blank">Distributed Computing with Spark SQL</a> - by UC Davis <a href="https://w.x.c" target="_blank">[Certificate]</a></b></summary>
<br>

- ***Course Summary:***
    - Learn distributed computing using Apache Spark and gain a thorough understanding of this open-source standard for working with large datasets. Learn fundamentals of data analysis using SQL on Spark. Learn the Spark architecture, queries within Spark, common ways to optimize Spark SQL, and how to build reliable data pipelines. 
    - By the end of this course, students will hone their SQL and distributed computing skills to become more adept at advanced analysis and to set the stage for transitioning to more advanced analytics as Data Scientists.<br><br>
- <details><summary><b><i>Course Content:</i></b></summary>        

    - **Introduction to Spark:** Learn to discuss the core concepts of distributed computing and be able to recognize when and where to apply them. Identify the basic data structure of Apache Spark, known as a DataFrame. Additionally, Use the collaborative Databricks workspace and write SQL code that executes against a cluster of machines.
    - **Spark Core Concepts:** Explain the core concepts of Spark. Learn common ways to increase query performance by caching data and modifying Spark configurations. Also use the Spark UI to analyze performance and identify bottlenecks, as well as optimize queries with Adaptive Query Execution.
    - **Engineering Data Pipelines:** Identify and discuss the general demands of data applications. Access data in a variety of formats and compare and contrast the tradeoffs between these formats. Explore and examine semi-structured JSON data (common in big data environments) as well as schemas and parallel data writes. Create an end-to-end pipeline that reads data, transforms it, and saves the result.
    - **Data Lakes, Warehouses and Lakehouses:** Identify the key characteristics of data lakes, data warehouses, and lakehouses. Lakehouses combine the scalability and low-cost storage of data lakes with the speed and ACID transactional guarantees of data warehouses. Build a production grade lakehouse by combining Spark with the open-source project, Delta Lake.
    </details>

- ***Tools & Libraries:*** Apache Spark, Spark SQL, Spark, Delta Lake.
- ***Techniques:*** Distributed computing, Caching data, Dataframe partitions, Adaptive Query Execution, Data pipelines, Data warehouses, Lakehouses.</details>
## Badge Decorations
<!--START_SECTION:badges-->
[![Data Science Professional Certificate](https://images.credly.com/size/110x110/images/28944969-813a-43b9-944f-7910111ce764/Professional_Certificate_-_Data_Science.png)](http://www.credly.com/badges/61e295e8-9853-46ba-8cb6-2f0e55e782ba "Data Science Professional Certificate")
[![Machine Learning with Python](https://images.credly.com/size/110x110/images/5ae9bf9e-da6e-4cec-82eb-d2b4cfea9751/Machine_Learning_with_Python.png)](http://www.credly.com/badges/25017f2a-2909-45d7-82d5-f9dc23b7c13f "Machine Learning with Python")
[![Data Visualization with Python](https://images.credly.com/size/110x110/images/76326afb-199d-4250-a74f-01bc86dda118/Cognitive_Class_-_Data_Visual_w_Python.png)](http://www.credly.com/badges/832c2b2c-df8e-4a94-9cb5-22a15c67d5de "Data Visualization with Python")
[![Data Analysis with Python](https://images.credly.com/size/110x110/images/fa39f4f0-174a-4886-b821-6a37d42b8b3a/Cognitive_Class_-_Data_Analysis_w_Python.png)](http://www.credly.com/badges/de199832-19b6-49cd-b242-40682f0ccc13 "Data Analysis with Python")
[![Data Science Orientation](https://images.credly.com/size/110x110/images/5fc2d535-e716-46c4-881a-f4822b8da0e5/Cognitive_Class_-_What_is_Data_Science.png)](http://www.credly.com/badges/0ec6598d-ae89-41ba-bfe2-c3b0de6ff5d7 "Data Science Orientation")
[![Data Science Methodology](https://images.credly.com/size/110x110/images/46defa53-a922-47bd-94ea-b43488f5cd8a/Data_Science_Methodology_Foundational.png)](http://www.credly.com/badges/f0bb3938-afd1-45ac-af26-cf788dee7b8f "Data Science Methodology")
[![Tools for Data Science](https://images.credly.com/size/110x110/images/60cf69ce-6129-425d-9a42-7732fa07da1e/Tools_for_Data_Science_Foundational.png)](http://www.credly.com/badges/521f1bfd-76d6-47a0-9701-c5f440fa88ea "Tools for Data Science")
[![Python for Data Science and AI](https://images.credly.com/size/110x110/images/0571ab1d-f43b-43d9-9c68-8ebd0ebd61b7/Python_for_Data_Sci_and_AI_Foundational.png)](http://www.credly.com/badges/823f0e3e-41aa-4a9c-8cf8-514d9714f39d "Python for Data Science and AI")
[![Project Management Professional (PMP)¬Æ](https://images.credly.com/size/110x110/images/260e36dc-d100-45c3-852f-9d8063fa71e6/pmp-600px.png)](http://www.credly.com/badges/b3d79fbf-e003-452c-b5ce-058b7eed99da "Project Management Professional (PMP)¬Æ")
<!--END_SECTION:badges-->
